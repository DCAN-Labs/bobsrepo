#!/bin/bash

subj_id=SUBJECTID
ses_id=SESID
data_bucket=BUCKET
data_upload=UPLOAD
deriv_upload=DERIVS
run_dir=RUNDIR
data_tier1=TIER1

# /tmp/ directories
data_msi_tmp=DATADIR
BIDS_DIR=${data_msi_tmp}/sub-${subj_id}
OUTPUT_DIR=${data_msi_tmp}/processed/dcan-infant-pipeline

# Function to stop processing if step failed to make logs clearer.
exit_err() {
    echo "${1}"
    exit 1
}

# Copy files from Tier 1 to temp
echo "=== Copy BIDS input data ==="
if [ ! -d ${data_msi_tmp}/sub-${subj_id}/ses-${ses_id} ]; then

    mkdir -p ${BIDS_DIR}

    cp -r \
        ${data_tier1}/sub-${subj_id}/ses-${ses_id}/ \
        ${data_msi_tmp}/sub-${subj_id}/ses-${ses_id} || \
    exit_err "BIDS copy failed"

fi

if [ ! -e ${data_msi_tmp}/dataset_description.json ]; then
    cp ${run_dir}/dataset_description.json ${data_msi_tmp}
fi

echo "Copying to ${data_msi_tmp}/sub-${subj_id}/ses-${ses_id} is done."

# Create processed and derivatives folders if they do not exist
mkdir -p ${data_msi_tmp}/processed/dcan-infant-pipeline/

echo
echo "=== Starting Pipeline ==="

faird_pl=/home/faird/shared/code/internal/pipelines
infant_abcd_bids_pipeline=${faird_pl}/DCAN-infant-BIDS/infant-abcd-bids-pipeline_v0.0.21.sif

echo "    Pipeline: ${infant_abcd_bids_pipeline}"

# THIS IS BCP SPECIFIC
if [ ${#ses_id} -ge 4 ] && [ ${ses_id:2} == 'mo' ]; then
    MONTH=${ses_id:0:2}
elif [ ${#ses_id} -ge 3 ] && [ ${ses_id:1} == 'mo' ]; then
    MONTH=${ses_id:0:1}
elif [ ${#ses_id} -ge 3 ] && [ ${ses_id:1} == 'wk' ]; then
    MONTH=0
elif [ ${#ses_id} -ge 4 ] && [ ${ses_id:2} == 'wk' ]; then
    MONTH=0
fi

if   [ "${MONTH}" -lt 0 ]; then
    echo "Invalid month <0: ${MONTH}, exiting"
    exit 1
elif [ "${MONTH}" -le 2 ] ; then
    template=00-02
elif [ "${MONTH}" -le 5 ] ; then
    template=02-05
elif [ "${MONTH}" -le 11 ] ; then
    template=08-11
elif [ "${MONTH}" -le 14 ] ; then
    template=11-14
elif [ "${MONTH}" -le 17 ] ; then
    template=14-17
elif [ "${MONTH}" -le 21 ] ; then
    template=17-21
elif [ "${MONTH}" -le 27 ] ; then
    template=21-27
elif [ "${MONTH}" -le 33 ] ; then
    template=27-33
elif [ "${MONTH}" -le 44 ] ; then
    template=33-44
elif [ "${MONTH}" -le 60 ] ; then
    template=44-60
else
    echo "Invalid month >60 ${MONTH}, exiting."
    exit 1
fi

BANDSTOP="16.8896 28.6662"
FS_LICENSE=/home/faird/shared/code/external/utilities/freesurfer_license
HNM=ROI_IPS
SMM=ROI_MAP
DCMETHOD=NONE
TEMPLATE_BIND=/home/elisonj/shared/BCP/lib/templates/${template}
NCPUS=12

lic_loc=/opt/freesurfer/license.txt

singularity run --cleanenv -e                           \
    -B ${data_msi_tmp}:/bids_input                      \
    -B ${OUTPUT_DIR}:/output                            \
    -B ${FS_LICENSE}/license.txt:${lic_loc}             \
    -B ${TEMPLATE_BIND}:/opt/pipeline/global/templates  \
    ${infant_abcd_bids_pipeline}                        \
        --freesurfer-license ${lic_loc}                 \
        --participant-label ${subj_id}                  \
        --session-id ${ses_id}                          \
        --bandstop ${BANDSTOP}                          \
        --hyper-normalization-method ${HNM}             \
        --subcortical-map-method ${SMM}                 \
        --dcmethod ${DCMETHOD}                          \
        --ncpus ${NCPUS}                                \
        --atropos-mask-method NONE                      \
        ANATONLY                                        \
        /bids_input                                     \
        /output || \
exit_err "Singularity run failed"

# Push processed outputs to bucket

echo
echo "=== Syncing processed outputs to bucket ==="
s3cmd sync -F --recursive -v \
    ${OUTPUT_DIR}/sub-${subj_id}/ses-${ses_id}/ \
    ${data_upload}/sub-${subj_id}/ses-${ses_id}/ || \
exit_err "Sync of processed outputs to bucket failed"

# Run filemapper

echo
echo "=== Starting filemapper ==="
mkdir -p ${data_msi_tmp}/derivatives/dcan-infant-pipeline

# Run filemapper to create derivatives
filemapper_json=/home/elisonj/shared/BCP/process/BCP-filemapper.json
/home/faird/shared/code/internal/utilities/file-mapper/file_mapper_script.py \
    "${filemapper_json}" \
    -a  copy \
    -sp ${data_msi_tmp}/  \
    -dp ${data_msi_tmp}/derivatives/dcan-infant-pipeline/ \
    -vb \
    -o \
    -t SUBJECT=${subj_id},SESSION=${ses_id},PIPELINE=dcan-infant-pipeline || \
exit_err "Filemapper failed"

# Push derivatives to bucket

echo
echo "=== Syncing derivatives to bucket ==="
s3cmd sync -F --recursive -v \
    ${data_msi_tmp}/derivatives/dcan-infant-pipeline/sub-${subj_id}/ses-${ses_id}/ \
    ${deriv_upload}/sub-${subj_id}/ses-${ses_id}/ || \
exit_err "Sync of derivatives failed"
